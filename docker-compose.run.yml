services:
  minio:
    image: minio/minio:RELEASE.2025-05-24T17-08-30Z    
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=minio123
    ports:
      - "9000:9000"   # S3  API
      - "9001:9001"   # Web console
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - lakehouse-net
      
  mc:
    image: minio/mc
    container_name: mc
    entrypoint: ["tail", "-f", "/dev/null"]   # Giữ container chạy để exec vào dùng lệnh mc
    depends_on:
      minio:
        condition: service_healthy  # Chờ MinIO sẵn sàng trước
    volumes:
      - ./services/minio:/scripts         
    networks:
      - lakehouse-net
    
  spark:
    image: lakehouse/spark:3.5.0
    container_name: spark
    depends_on:
      - minio
    networks:
      - lakehouse-net
    ports:
      - "4040:4040"
    volumes:
      - ./services/spark/jobs:/opt/bitnami/spark/spark_jobs 
  
  metastore-db:
    container_name: metastore-db
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=root123
      - MYSQL_DATABASE=metastore
      - MYSQL_USER=hive
      - MYSQL_PASSWORD=hive123
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "hive", "-phive123"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lakehouse-net

  hive-metastore:
    container_name: hive-metastore
    image: lakehouse/hive-metastore:4.0.0
    environment:
      - SERVICE_NAME=metastore
    depends_on:
      metastore-db:
        condition: service_healthy
    ports:
      - "9083:9083"
    networks:
      - lakehouse-net
  
  trino:
    image: lakehouse/trino:468
    container_name: trino
    ports:
      - "8081:8080"
    volumes:
      - ./services/trino/catalog:/etc/trino/catalog
      - ./services/trino/conf/config.properties:/etc/trino/config.properties
      - ./services/trino/conf/jvm.config:/etc/trino/jvm.config
      - ./services/trino/conf/node.properties:/etc/trino/node.properties
      - ./services/trino/conf/log.properties:/etc/trino/log.properties
    depends_on:
      - hive-metastore
      - minio
    networks:
      - lakehouse-net
  
  superset:
    image: lakehouse/superset:4.1.2
    container_name: superset
    ports:
      - "8088:8088"
    environment:
      - ADMIN_USERNAME=admin
      - ADMIN_PASSWORD=admin123
      - ADMIN_EMAIL=admin@localhost
      - SUPERSET_SECRET_KEY=thisisaverysecretkey
    volumes:
      - ./services/superset/pythonpath:/app/pythonpath
      - ./services/superset/superset_home:/app/superset_home
    networks:
      - lakehouse-net
    depends_on:
      - trino
    
  zookeeper:
    image: bitnami/zookeeper:3.8.4
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_4LW_COMMANDS_WHITELIST=ruok,srvr,mntr
    ports:
      - "2181:2181"
    networks:
      - lakehouse-net
    healthcheck:
      test: ["CMD", "/opt/bitnami/scripts/zookeeper/healthcheck.sh"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: lakehouse/kafka:3.9.0
    container_name: kafka
    environment:
      # ZooKeeper
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_BROKER_ID=1

      # Lắng nghe hai interface
      - KAFKA_CFG_LISTENERS=INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094

      # Thông báo cho clients hai địa chỉ
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:9094

      # Cả hai đều PLAINTEXT
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT

      # Dùng INTERNAL làm inter-broker
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9094:9094"
    networks:
      - lakehouse-net

  airflow-db:
    image: postgres:15
    container_name: airflow-db
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - airflow-db-data:/var/lib/postgresql/data
    networks:
      - lakehouse-net

  airflow-webserver:
    image: lakehouse/airflow:2.9.2
    container_name: airflow-webserver
    depends_on:
      - airflow-db
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: supersecret
      # --- tự upgrade DB & tạo admin ---
      _AIRFLOW_DB_UPGRADE: "true"
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin123
      _AIRFLOW_WWW_USER_FIRSTNAME: Admin
      _AIRFLOW_WWW_USER_LASTNAME: User
      _AIRFLOW_WWW_USER_EMAIL: admin@example.com
    volumes:
      - ./services/airflow/dags:/opt/airflow/dags
      - ./services/airflow/plugins:/opt/airflow/plugins
      - ./services/airflow/logs:/opt/airflow/logs
      - ./tools:/opt/airflow/tools
      - ./data:/opt/airflow/data
    ports:
      - "8082:8080"
    networks:
      - lakehouse-net
    command: webserver

  airflow-scheduler:
    image: lakehouse/airflow:2.9.2
    container_name: airflow-scheduler
    depends_on:
      - airflow-db
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db:5432/airflow
      AIRFLOW__CORE__FERNET_KEY: supersecret
      _AIRFLOW_DB_UPGRADE: "true"    # để scheduler cũng tự đảm bảo DB khớp
    volumes:
      - ./services/airflow/dags:/opt/airflow/dags
      - ./services/airflow/plugins:/opt/airflow/plugins
      - ./services/airflow/logs:/opt/airflow/logs
      - ./tools:/opt/airflow/tools
      - ./data:/opt/airflow/data
    networks:
      - lakehouse-net
    command: scheduler

volumes:
  minio-data:
  airflow-db-data:

networks:
  lakehouse-net:
    driver: bridge
